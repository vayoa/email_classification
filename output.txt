‚ùØ python train_modernbert_email_classifiers.py   --csv ./email_dataset.csv   --text-col text   --epochs 3  --max-length 2048 --batch-size 8
Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.
{'loss': 7.4148, 'grad_norm': 19.125, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.07}
{'loss': 7.1323, 'grad_norm': 91.0, 'learning_rate': 1.814814814814815e-05, 'epoch': 0.14}
{'loss': 6.5899, 'grad_norm': 30.875, 'learning_rate': 1.9607843137254903e-05, 'epoch': 0.21}
{'loss': 5.872, 'grad_norm': 35.75, 'learning_rate': 1.911764705882353e-05, 'epoch': 0.28}
{'loss': 5.0543, 'grad_norm': 34.75, 'learning_rate': 1.862745098039216e-05, 'epoch': 0.35}
{'loss': 3.9311, 'grad_norm': 67.5, 'learning_rate': 1.8137254901960785e-05, 'epoch': 0.42}
{'loss': 2.8404, 'grad_norm': 38.5, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.49}
{'loss': 1.6383, 'grad_norm': 42.25, 'learning_rate': 1.715686274509804e-05, 'epoch': 0.56}
{'loss': 1.0876, 'grad_norm': 27.875, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.63}
{'loss': 0.9676, 'grad_norm': 22.375, 'learning_rate': 1.6176470588235296e-05, 'epoch': 0.7}
{'loss': 0.8362, 'grad_norm': 107.0, 'learning_rate': 1.568627450980392e-05, 'epoch': 0.77}
{'loss': 0.734, 'grad_norm': 44.25, 'learning_rate': 1.519607843137255e-05, 'epoch': 0.84}
{'loss': 0.64, 'grad_norm': 11.625, 'learning_rate': 1.4705882352941179e-05, 'epoch': 0.91}
{'loss': 0.6217, 'grad_norm': 41.75, 'learning_rate': 1.4215686274509805e-05, 'epoch': 0.98}
{'eval_loss': 0.14302770793437958, 'eval_accuracy': 0.9658753709198813, 'eval_macro_f1': 0.9658593801124669, 'eval_weighted_f1': 0.9658672704490755, 'eval_macro_precision': 0.9659382359210816, 'eval_macro_recall': 0.9658780969911419, 'eval_runtime': 33.1639, 'eval_samples_per_second': 60.97, 'eval_steps_per_second': 15.258, 'epoch': 1.0}       
{'loss': 0.5819, 'grad_norm': 31.0, 'learning_rate': 1.3725490196078432e-05, 'epoch': 1.05}
{'loss': 0.4691, 'grad_norm': 23.0, 'learning_rate': 1.323529411764706e-05, 'epoch': 1.12}
{'loss': 0.5262, 'grad_norm': 38.5, 'learning_rate': 1.2745098039215686e-05, 'epoch': 1.19}                                                                                                                                                                                                                                                                
{'loss': 0.4692, 'grad_norm': 35.25, 'learning_rate': 1.2254901960784315e-05, 'epoch': 1.26}                                                                                                                                                                                                                                                               
{'loss': 0.5278, 'grad_norm': 28.0, 'learning_rate': 1.1764705882352942e-05, 'epoch': 1.33}                                                                                                                                                                                                                                                                
{'loss': 0.5036, 'grad_norm': 11.1875, 'learning_rate': 1.1274509803921569e-05, 'epoch': 1.4}                                                                                                                                                                                                                                                              
{'loss': 0.4478, 'grad_norm': 30.375, 'learning_rate': 1.0784313725490196e-05, 'epoch': 1.47}                                                                                                                                                                                                                                                              
{'loss': 0.3534, 'grad_norm': 23.0, 'learning_rate': 1.0294117647058823e-05, 'epoch': 1.54}                                                                                                                                                                                                                                                                
{'loss': 0.4438, 'grad_norm': 26.375, 'learning_rate': 9.803921568627451e-06, 'epoch': 1.61}                                                                                                                                                                                                                                                               
{'loss': 0.5346, 'grad_norm': 25.875, 'learning_rate': 9.31372549019608e-06, 'epoch': 1.68}                                                                                                                                                                                                                                                                
{'loss': 0.389, 'grad_norm': 14.6875, 'learning_rate': 8.823529411764707e-06, 'epoch': 1.75}                                                                                                                                                                                                                                                               
{'loss': 0.4552, 'grad_norm': 43.75, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.82}                                                                                                                                                                                                                                                                
{'loss': 0.4357, 'grad_norm': 44.25, 'learning_rate': 7.84313725490196e-06, 'epoch': 1.89}                                                                                                                                                                                                                                                                 
{'loss': 0.3234, 'grad_norm': 28.0, 'learning_rate': 7.352941176470589e-06, 'epoch': 1.96}                                                                                                                                                                                                                                                                 
{'eval_loss': 0.10129155218601227, 'eval_accuracy': 0.9713155291790306, 'eval_macro_f1': 0.971324960870298, 'eval_weighted_f1': 0.971337977629761, 'eval_macro_precision': 0.9714359081407133, 'eval_macro_recall': 0.9713153636986666, 'eval_runtime': 33.1269, 'eval_samples_per_second': 61.038, 'eval_steps_per_second': 15.275, 'epoch': 2.0}         
{'loss': 0.4508, 'grad_norm': 26.0, 'learning_rate': 6.862745098039216e-06, 'epoch': 2.03}                                                                                                                                                                                                                                                                 
{'loss': 0.3527, 'grad_norm': 57.0, 'learning_rate': 6.372549019607843e-06, 'epoch': 2.09}
{'loss': 0.417, 'grad_norm': 11.75, 'learning_rate': 5.882352941176471e-06, 'epoch': 2.16}                                                                                                                                                                                                                                                                 
{'loss': 0.3697, 'grad_norm': 23.625, 'learning_rate': 5.392156862745098e-06, 'epoch': 2.23}                                                                                                                                                                                                                                                               
{'loss': 0.3574, 'grad_norm': 29.125, 'learning_rate': 4.901960784313726e-06, 'epoch': 2.3}                                                                                                                                                                                                                                                                
{'loss': 0.4207, 'grad_norm': 43.5, 'learning_rate': 4.411764705882353e-06, 'epoch': 2.37}                                                                                                                                                                                                                                                                 
{'loss': 0.3752, 'grad_norm': 42.25, 'learning_rate': 3.92156862745098e-06, 'epoch': 2.44}                                                                                                                                                                                                                                                                 
{'loss': 0.3578, 'grad_norm': 10.9375, 'learning_rate': 3.431372549019608e-06, 'epoch': 2.51}                                                                                                                                                                                                                                                              
{'loss': 0.446, 'grad_norm': 15.3125, 'learning_rate': 2.9411764705882355e-06, 'epoch': 2.58}                                                                                                                                                                                                                                                              
{'loss': 0.3892, 'grad_norm': 7.5, 'learning_rate': 2.450980392156863e-06, 'epoch': 2.65}                                                                                                                                                                                                                                                                  
{'loss': 0.4138, 'grad_norm': 31.875, 'learning_rate': 1.96078431372549e-06, 'epoch': 2.72}                                                                                                                                                                                                                                                                
{'loss': 0.3717, 'grad_norm': 20.375, 'learning_rate': 1.4705882352941177e-06, 'epoch': 2.79}                                                                                                                                                                                                                                                              
{'loss': 0.3866, 'grad_norm': 100.5, 'learning_rate': 9.80392156862745e-07, 'epoch': 2.86}                                                                                                                                                                                                                                                                 
{'loss': 0.4371, 'grad_norm': 39.5, 'learning_rate': 4.901960784313725e-07, 'epoch': 2.93}                                                                                                                                                                                                                                                                 
{'eval_loss': 0.09746525436639786, 'eval_accuracy': 0.9723046488625123, 'eval_macro_f1': 0.9723165977619219, 'eval_weighted_f1': 0.9723289489839873, 'eval_macro_precision': 0.9724017322653099, 'eval_macro_recall': 0.9723030201873503, 'eval_runtime': 33.2245, 'eval_samples_per_second': 60.859, 'eval_steps_per_second': 15.23, 'epoch': 3.0}        
{'train_runtime': 1267.6518, 'train_samples_per_second': 27.109, 'train_steps_per_second': 0.847, 'train_loss': 1.344891928205721, 'epoch': 3.0}                                                                                                                                                                                                           
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1074/1074 [21:07<00:00,  1.18s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 506/506 [00:19<00:00, 26.41it/s]
Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.
{'loss': 3.1208, 'grad_norm': 76.0, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.07}
{'loss': 2.936, 'grad_norm': 24.5, 'learning_rate': 1.814814814814815e-05, 'epoch': 0.14}                                                                                                                                                                                                                                                                  
{'loss': 2.6254, 'grad_norm': 26.25, 'learning_rate': 1.9607843137254903e-05, 'epoch': 0.21}                                                                                                                                                                                                                                                               
{'loss': 2.3815, 'grad_norm': 165.0, 'learning_rate': 1.911764705882353e-05, 'epoch': 0.28}                                                                                                                                                                                                                                                                
{'loss': 2.1505, 'grad_norm': 79.5, 'learning_rate': 1.862745098039216e-05, 'epoch': 0.35}                                                                                                                                                                                                                                                                 
{'loss': 1.9764, 'grad_norm': 33.5, 'learning_rate': 1.8137254901960785e-05, 'epoch': 0.42}                                                                                                                                                                                                                                                                
{'loss': 1.7694, 'grad_norm': 28.625, 'learning_rate': 1.7647058823529414e-05, 'epoch': 0.49}                                                                                                                                                                                                                                                              
{'loss': 1.5094, 'grad_norm': 40.75, 'learning_rate': 1.715686274509804e-05, 'epoch': 0.56}                                                                                                                                                                                                                                                                
{'loss': 1.4014, 'grad_norm': 45.25, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.63}                                                                                                                                                                                                                                                               
{'loss': 1.2522, 'grad_norm': 38.75, 'learning_rate': 1.6176470588235296e-05, 'epoch': 0.7}                                                                                                                                                                                                                                                                
{'loss': 1.2168, 'grad_norm': 40.5, 'learning_rate': 1.568627450980392e-05, 'epoch': 0.77}                                                                                                                                                                                                                                                                 
{'loss': 1.2868, 'grad_norm': 36.25, 'learning_rate': 1.519607843137255e-05, 'epoch': 0.84}                                                                                                                                                                                                                                                                
{'loss': 0.9832, 'grad_norm': 37.0, 'learning_rate': 1.4705882352941179e-05, 'epoch': 0.91}                                                                                                                                                                                                                                                                
{'loss': 1.3101, 'grad_norm': 21.25, 'learning_rate': 1.4215686274509805e-05, 'epoch': 0.98}                                                                                                                                                                                                                                                               
{'eval_loss': 0.2793927490711212, 'eval_accuracy': 0.8813056379821959, 'eval_precision': 0.6564195298372514, 'eval_recall': 0.8789346246973365, 'eval_f1': 0.7515527950310559, 'eval_roc_auc': 0.9502804292440976, 'eval_runtime': 33.5909, 'eval_samples_per_second': 60.195, 'eval_steps_per_second': 15.064, 'epoch': 1.0}                              
{'loss': 0.9225, 'grad_norm': 33.5, 'learning_rate': 1.3725490196078432e-05, 'epoch': 1.05}                                                                                                                                                                                                                                                                
{'loss': 1.1145, 'grad_norm': 58.75, 'learning_rate': 1.323529411764706e-05, 'epoch': 1.12}
{'loss': 1.0641, 'grad_norm': 20.875, 'learning_rate': 1.2745098039215686e-05, 'epoch': 1.19}                                                                                                                                                                                                                                                              
{'loss': 1.0372, 'grad_norm': 56.25, 'learning_rate': 1.2254901960784315e-05, 'epoch': 1.26}                                                                                                                                                                                                                                                               
{'loss': 0.8969, 'grad_norm': 67.5, 'learning_rate': 1.1764705882352942e-05, 'epoch': 1.33}                                                                                                                                                                                                                                                                
{'loss': 1.0946, 'grad_norm': 21.875, 'learning_rate': 1.1274509803921569e-05, 'epoch': 1.4}                                                                                                                                                                                                                                                               
{'loss': 0.8532, 'grad_norm': 31.25, 'learning_rate': 1.0784313725490196e-05, 'epoch': 1.47}                                                                                                                                                                                                                                                               
{'loss': 0.9598, 'grad_norm': 114.0, 'learning_rate': 1.0294117647058823e-05, 'epoch': 1.54}                                                                                                                                                                                                                                                               
{'loss': 0.8075, 'grad_norm': 45.5, 'learning_rate': 9.803921568627451e-06, 'epoch': 1.61}                                                                                                                                                                                                                                                                 
{'loss': 0.9046, 'grad_norm': 46.75, 'learning_rate': 9.31372549019608e-06, 'epoch': 1.68}                                                                                                                                                                                                                                                                 
{'loss': 0.9618, 'grad_norm': 27.375, 'learning_rate': 8.823529411764707e-06, 'epoch': 1.75}                                                                                                                                                                                                                                                               
{'loss': 0.9115, 'grad_norm': 19.375, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.82}                                                                                                                                                                                                                                                               
{'loss': 0.9187, 'grad_norm': 45.0, 'learning_rate': 7.84313725490196e-06, 'epoch': 1.89}                                                                                                                                                                                                                                                                  
{'loss': 0.7618, 'grad_norm': 47.75, 'learning_rate': 7.352941176470589e-06, 'epoch': 1.96}                                                                                                                                                                                                                                                                
{'eval_loss': 0.23504556715488434, 'eval_accuracy': 0.9179030662710188, 'eval_precision': 0.7762863534675615, 'eval_recall': 0.8401937046004843, 'eval_f1': 0.8069767441860465, 'eval_roc_auc': 0.9628248788217608, 'eval_runtime': 33.9233, 'eval_samples_per_second': 59.605, 'eval_steps_per_second': 14.916, 'epoch': 2.0}                             
{'loss': 0.7803, 'grad_norm': 31.5, 'learning_rate': 6.862745098039216e-06, 'epoch': 2.03}                                                                                                                                                                                                                                                                 
{'loss': 0.889, 'grad_norm': 88.5, 'learning_rate': 6.372549019607843e-06, 'epoch': 2.09}
{'loss': 0.764, 'grad_norm': 23.0, 'learning_rate': 5.882352941176471e-06, 'epoch': 2.16}                                                                                                                                                                                                                                                                  
{'loss': 0.8138, 'grad_norm': 33.75, 'learning_rate': 5.392156862745098e-06, 'epoch': 2.23}                                                                                                                                                                                                                                                                
{'loss': 0.8596, 'grad_norm': 46.5, 'learning_rate': 4.901960784313726e-06, 'epoch': 2.3}                                                                                                                                                                                                                                                                  
{'loss': 0.8572, 'grad_norm': 28.625, 'learning_rate': 4.411764705882353e-06, 'epoch': 2.37}                                                                                                                                                                                                                                                               
{'loss': 0.7161, 'grad_norm': 64.0, 'learning_rate': 3.92156862745098e-06, 'epoch': 2.44}                                                                                                                                                                                                                                                                  
{'loss': 0.9195, 'grad_norm': 57.25, 'learning_rate': 3.431372549019608e-06, 'epoch': 2.51}                                                                                                                                                                                                                                                                
{'loss': 0.8345, 'grad_norm': 32.0, 'learning_rate': 2.9411764705882355e-06, 'epoch': 2.58}                                                                                                                                                                                                                                                                
{'loss': 0.7981, 'grad_norm': 44.5, 'learning_rate': 2.450980392156863e-06, 'epoch': 2.65}                                                                                                                                                                                                                                                                 
{'loss': 1.0073, 'grad_norm': 58.75, 'learning_rate': 1.96078431372549e-06, 'epoch': 2.72}                                                                                                                                                                                                                                                                 
{'loss': 0.7735, 'grad_norm': 82.5, 'learning_rate': 1.4705882352941177e-06, 'epoch': 2.79}                                                                                                                                                                                                                                                                
{'loss': 1.0282, 'grad_norm': 40.5, 'learning_rate': 9.80392156862745e-07, 'epoch': 2.86}                                                                                                                                                                                                                                                                  
{'loss': 0.8085, 'grad_norm': 45.0, 'learning_rate': 4.901960784313725e-07, 'epoch': 2.93}                                                                                                                                                                                                                                                                 
{'eval_loss': 0.22975152730941772, 'eval_accuracy': 0.9144411473788329, 'eval_precision': 0.7521008403361344, 'eval_recall': 0.8668280871670703, 'eval_f1': 0.8053993250843644, 'eval_roc_auc': 0.9642236391243565, 'eval_runtime': 33.4862, 'eval_samples_per_second': 60.383, 'eval_steps_per_second': 15.111, 'epoch': 3.0}                             
{'train_runtime': 1294.3886, 'train_samples_per_second': 26.549, 'train_steps_per_second': 0.83, 'train_loss': 1.2081587203610098, 'epoch': 3.0}                                                                                                                                                                                                           
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1074/1074 [21:34<00:00,  1.21s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 506/506 [00:19<00:00, 25.97it/s]
{
  "category": {
    "eval_loss": 0.09746525436639786,
    "eval_accuracy": 0.9723046488625123,
    "eval_macro_f1": 0.9723165977619219,
    "eval_weighted_f1": 0.9723289489839873,
    "eval_macro_precision": 0.9724017322653099,
    "eval_macro_recall": 0.9723030201873503,
    "eval_runtime": 32.9246,
    "eval_samples_per_second": 61.413,
    "eval_steps_per_second": 15.368,
    "epoch": 3.0
  },
  "important": {
    "eval_loss": 0.23504556715488434,
    "eval_accuracy": 0.9179030662710188,
    "eval_precision": 0.7762863534675615,
    "eval_recall": 0.8401937046004843,
    "eval_f1": 0.8069767441860465,
    "eval_roc_auc": 0.9628248788217608,
    "eval_runtime": 33.1333,
    "eval_samples_per_second": 61.026,
    "eval_steps_per_second": 15.272,
    "epoch": 3.0
  },
  "output_dirs": {
    "category": "outputs\\modernbert_category",
    "important": "outputs\\modernbert_important"
  },
  "model_name": "answerdotai/ModernBERT-base",
  "max_length": 2048
}